{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MUJOCO_GL=egl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metaworld.envs import ALL_V2_ENVIRONMENTS_GOAL_OBSERVABLE\n",
    "\n",
    "%env MUJOCO_GL=egl\n",
    "\n",
    "cls = ALL_V2_ENVIRONMENTS_GOAL_OBSERVABLE[\"reach-v2-goal-observable\"]\n",
    "env = cls(seed=1)\n",
    "env.observation_space.shape\n",
    "env.reset()\n",
    "len(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjlee/miniconda3/lib/python3.8/site-packages/torch/cuda/__init__.py:104: UserWarning: \n",
      "NVIDIA RTX A6000 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70 sm_75.\n",
      "If you want to use the NVIDIA RTX A6000 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstable_baselines3\u001b[39;00m \u001b[39mimport\u001b[39;00m SAC\n\u001b[0;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m SAC(\n\u001b[1;32m      3\u001b[0m     policy\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mMlpPolicy\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m     env\u001b[39m=\u001b[39;49menv,\n\u001b[1;32m      5\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     tensorboard_log\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/ext_hdd/jjlee/jumpstart-rl/logs/_guide_\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m     learning_rate\u001b[39m=\u001b[39;49m\u001b[39m3e-4\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m     buffer_size\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(\u001b[39m1e6\u001b[39;49m),\n\u001b[1;32m      9\u001b[0m     learning_starts\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m     tau\u001b[39m=\u001b[39;49m\u001b[39m0.005\u001b[39;49m,\n\u001b[1;32m     12\u001b[0m     gamma\u001b[39m=\u001b[39;49m\u001b[39m0.99\u001b[39;49m,\n\u001b[1;32m     13\u001b[0m     train_freq\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     14\u001b[0m     gradient_steps\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     15\u001b[0m     action_noise\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     16\u001b[0m     optimize_memory_usage\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     17\u001b[0m     target_update_interval\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     18\u001b[0m     target_entropy\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     19\u001b[0m     use_sde\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     20\u001b[0m     sde_sample_freq\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     21\u001b[0m     policy_kwargs\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/stable_baselines3/sac/sac.py:157\u001b[0m, in \u001b[0;36mSAC.__init__\u001b[0;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, action_noise, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, ent_coef, target_update_interval, target_entropy, use_sde, sde_sample_freq, use_sde_at_warmup, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ment_coef_optimizer: Optional[th\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m _init_setup_model:\n\u001b[0;32m--> 157\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_model()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/stable_baselines3/sac/sac.py:186\u001b[0m, in \u001b[0;36mSAC._setup_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[39massert\u001b[39;00m init_value \u001b[39m>\u001b[39m \u001b[39m0.0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mThe initial value of ent_coef must be greater than 0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    184\u001b[0m     \u001b[39m# Note: we optimize the log of the entropy coeff which is slightly different from the paper\u001b[39;00m\n\u001b[1;32m    185\u001b[0m     \u001b[39m# as discussed in https://github.com/rail-berkeley/softlearning/issues/37\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_ent_coef \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mlog(th\u001b[39m.\u001b[39;49mones(\u001b[39m1\u001b[39;49m, device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice) \u001b[39m*\u001b[39m init_value)\u001b[39m.\u001b[39mrequires_grad_(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    187\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ment_coef_optimizer \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_ent_coef], lr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_schedule(\u001b[39m1\u001b[39m))\n\u001b[1;32m    188\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[39m# Force conversion to float\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     \u001b[39m# this will throw an error if a malformed string (different from 'auto')\u001b[39;00m\n\u001b[1;32m    191\u001b[0m     \u001b[39m# is passed\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import SAC\n",
    "model = SAC(\n",
    "    policy=\"MlpPolicy\",\n",
    "    env=env,\n",
    "    verbose=1,\n",
    "    tensorboard_log=\"/ext_hdd/jjlee/jumpstart-rl/logs/_guide_\",\n",
    "    learning_rate=3e-4,\n",
    "    buffer_size=int(1e6),\n",
    "    learning_starts=1000,\n",
    "    batch_size=256,\n",
    "    tau=0.005,\n",
    "    gamma=0.99,\n",
    "    train_freq=1,\n",
    "    gradient_steps=1,\n",
    "    action_noise=None,\n",
    "    optimize_memory_usage=False,\n",
    "    target_update_interval=1,\n",
    "    target_entropy=\"auto\",\n",
    "    use_sde=False,\n",
    "    sde_sample_freq=-1,\n",
    "    policy_kwargs=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
